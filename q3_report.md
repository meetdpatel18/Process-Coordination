## CONSTRAINTS
INPUT CAN BE POSITIVE OR NEGATIVE NUMBER

# SHARED MEMORY AND FORK IMPLEMENTATION
- INPUT SIZE MUST NOT BE TOO LARGE (~1000) BECAUSE LARGE INPUT SIZE WILL LEAD TO MORE FORK CALLS AND WILL LEAD TO EVENTUALY LEAD TO SEGMENTATION FAULT AS MAIN MEMORY IS LIMITED
- WE CREATED A SHARED MEMORY USING SHMGET,SHMAT OF SIZE EQUAL TO INPUT SIZE OF AN ARRAY
- THEN WE ARE RECURSIVELY CALLING FORK FOR LEFT AND RIGHT CHILD FOR MERGESORT IMPLEMENTATION
- WE WILL WAIT FOR CHILD PROCESS TO COMPLETE THEN WE WILL MERGE 



# THREAD IMPLEMENTATION
- INPUT SIZE MUST NOT BE TOO LARGE (~1000) BECAUSE LARGE INPUT WILL LEAD TO CREATION OF TOO MANY THREADS WHICH WILL EVENTUALLY LEAD TO SEGMENTATION FAULT BECAUSE THREADS PER PROCESS ARE LIMITED IN LINUX
- NEW THREAD WILL BE CREATED FOR EACH MERGESORT RECURSIVE CALL 
- WE WILL WAIT FOR RECURSIVE CALLS TO COMPLETE BEFORE MERGING THEM
- I HAVE DECLARED A VECTOR IN GLOBALLY SO THAT ALL THREADS CAN SHARE THIS


# PERFORMANCE REPORT
- THREAD IMPLEMENTATION IS FASTER THAN FORK IMPLEMENTATION:
    - BECAUSE IN FORK IMPLEMENTATION FOR BOTH RIGHT AND LEFT CHILD PROCESSES THERE WILL BE CACHE MISS 
     THIS WILL LEAD TO DEGRADATION IN PERFORMANCE 
    - IN THREAD IMPLEMENTATION RECUSRSIVE CALLS CAN ACCESS VECTOR AT THE SAME TIME CONCURRENTLY BECAUSE IT IS DECLARED IN A GLOBAL SCOPE AND THERE WILL NOT BE CACHE MISS      FOR EACH RECURSIVE CALLS

## FINAL RESULT
- NORMAL IMPLEMENTAION > THREAD IMPLEMENTATION > FORK IMPLEMENTATION

- NORMAL IMPLEMENTATION IS FASTER THAN THREAD AND FORK 
- THREAD IMPLEMENTATION IS FASTER THAN FORK
