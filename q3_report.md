### CONSTRAINTS
INPUT CAN BE POSITIVE OR NEGATIVE NUMBER

# SHARED MEMORY AND FORK IMPLEMENTATION
1.INPUT SIZE MUST NOT BE TOO LARGE (~1000) BECAUSE LARGE INPUT SIZE WILL LEAD TO MORE FORK CALLS AND WILL LEAD TO EVENTUALY LEAD TO SEGMENTATION FAULT AS MAIN MEMORY IS LIMITED
2.WE CREATED A SHARED MEMORY USING SHMGET,SHMAT OF SIZE EQUAL TO INPUT SIZE OF AN ARRAY
3.THEN WE ARE RECURSIVELY CALLING FORK FOR LEFT AND RIGHT CHILD FOR MERGESORT IMPLEMENTATION
4.WE WILL WAIT FOR CHILD PROCESS TO COMPLETE THEN WE WILL MERGE 



# THREAD IMPLEMENTATION
1.INPUT SIZE MUST NOT BE TOO LARGE (~1000) BECAUSE LARGE INPUT WILL LEAD TO CREATION OF TOO MANY THREADS WHICH WILL EVENTUALLY LEAD TO SEGMENTATION FAULT BECAUSE THREADS PER PROCESS ARE LIMITED IN LINUX
2.NEW THREAD WILL BE CREATED FOR EACH MERGESORT RECURSIVE CALL 
3.WE WILL WAIT FOR RECURSIVE CALLS TO COMPLETE BEFORE MERGING THEM
4.I HAVE DECLARED A VECTOR IN GLOBALLY SO THAT ALL THREADS CAN SHARE THIS


# PERFORMANCE REPORT
1.THREAD IMPLEMENTATION IS FASTER THAN FORK IMPLEMENTATION:
    BECAUSE IN FORK IMPLEMENTATION WHEN FOR BOTH RIGHT AND LEFT CHILD PROCESSES THERE WILL BE CACHE MISS 
    THIS WILL LEAD TO DEGRADATION IN PERFORMANCE 
    IN THREAD IMPLEMENTATION RECUSRSIVE CALLS CAN ACCESS VECTOR AT THE SAME TIME CONCURRENTLY BECAUSE IT IS DECLARED IN A GLOBAL SCOPE AND THERE WILL NOT BE CACHE MISS FOR EACH RECURSIVE CALLS

## FINAL RESULT
1.NORMAL IMPLEMENTAION > THREAD IMPLEMENTATION > FORK IMPLEMENTATION

2.NORMAL IMPLEMENTATION IS FASTER THAN THREAD AND FORK 
3.THREAD IMPLEMENTATION IS FASTER THAN FORK
